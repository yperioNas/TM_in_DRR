{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb30531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#read the 20** excel \n",
    "df = pd.read_excel(\"dataset_2017.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6001ef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_abstract = df[\"Abstract\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c2a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import io\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "\n",
    "import string\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73394640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punctuation(text):\n",
    "    \n",
    "    clean_text_from_punc = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    return clean_text_from_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1160334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "\n",
    "    clean_text_from_stop_words = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    words = text.split()\n",
    "    for r in words:\n",
    "        if not r in stop_words and len(r) >= 3:\n",
    "            clean_text_from_stop_words.append(r)\n",
    "\n",
    "    clean_text_from_stop_words = \" \".join(clean_text_from_stop_words)\n",
    "\n",
    "    return (clean_text_from_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcec73a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    lematize_text = []\n",
    "    # Init the Wordnet Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for word in text:\n",
    "        lemmatizer_word = lemmatizer.lemmatize(word)\n",
    "        lematize_text.append(lemmatizer_word)\n",
    "    return lematize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d9369da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['evacuation', 'think', 'most', 'effective', 'method', 'protect', 'life', 'tsunamis']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def lemmatization_spacy(text , allowed_postags = [\"NOUN\",\"VERB\",\"ADJ\",\"ADV\",\"NUM\",\"PRON\"]):\n",
    "    nlp = spacy.load(\"en_core_web_sm\",disable=[\"parser\",\"ner\"])\n",
    "    \n",
    "\n",
    "    doc = nlp(text)\n",
    "    lemmatize_text = []\n",
    "    for token in doc:\n",
    "        if token.pos_ in allowed_postags:\n",
    "            lemmatize_text.append(token.lemma_)\n",
    "    return lemmatize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "128b8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "\n",
    "    token_list= []\n",
    "    for line in text:\n",
    "       token = gensim.utils.simple_preprocess( line, deacc=True)\n",
    "       token_list.append(''.join(token))\n",
    "       token_list = list(filter(None, token_list))\n",
    "    return token_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23f9cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(list_abstract):\n",
    "    clean_texts = []\n",
    "    for text in list_abstract:\n",
    "\n",
    "        clean_text = remove_punctuation(text)\n",
    "\n",
    "        clean_text = remove_stopwords(clean_text)\n",
    "\n",
    "        clean_text = lemmatization_spacy(clean_text)\n",
    "\n",
    "        clean_text = tokenization(clean_text)\n",
    "\n",
    "        clean_texts.append(clean_text)\n",
    "    \n",
    "    return clean_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cb76bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_preprocessing_text = preprocessing(list_abstract)\n",
    "clean_preprocessing_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59773eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "sentences = str(clean_preprocessing_text)\n",
    "sentences_as_one_string = \"\".join(sentences)\n",
    "s = remove_punctuation(sentences_as_one_string)\n",
    "\n",
    "wordcloud = WordCloud(max_font_size=50, max_words=50, background_color=\"white\").generate(s)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cf9a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Vectorization\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "# Create Dictionary\n",
    "dictionary = corpora.Dictionary(clean_preprocessing_text)\n",
    "# Create Corpus List\n",
    "corpus = []\n",
    "# Term Document Frequency\n",
    "for text in clean_preprocessing_text:\n",
    "    new_text = dictionary.doc2bow(text)\n",
    "    corpus.append(new_text)\n",
    "#Display\n",
    "corpus[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee85977f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#TfidfModel\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(clean_preprocessing_text)\n",
    "# Create Corpus\n",
    "corpus = []\n",
    "tfidf   = gensim.models.TfidfModel(dictionary=id2word, normalize=True)\n",
    "# Term Document Frequency\n",
    "for text in clean_preprocessing_text:\n",
    "    new_text = tfidf[id2word.doc2bow(text)]\n",
    "    corpus.append(new_text)\n",
    "# View\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c6bd3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=4, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1d34e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "visual_LDA = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "visual_LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bcd72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_matrix = {}\n",
    "  \n",
    "for idx, topic in lda_model.show_topics(formatted=False, num_words= 10):\n",
    "    w1 = [w[0] for w in topic]\n",
    "    topics_matrix[f\"Topic {1+idx}\"] =  w1\n",
    "    \n",
    "print(topics_matrix)\n",
    "\n",
    "df = pd.DataFrame(data=topics_matrix,)\n",
    "df.style.set_properties(**{'border': '1.3px solid green','color': 'magenta'})\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb5aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Keyword in the x topics\n",
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87405a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lda = lda_model[corpus]\n",
    "print(doc_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c6120dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score:  0.23884053567482622\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('Perplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=clean_preprocessing_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_LDA = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d88b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=num_topics, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "        model_list.append(lda_model)\n",
    "        coherencemodel = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc2db58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n",
    "\n",
    "print(model_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58794f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the most optimal model LDA\n",
    "optimal_model = model_list[2]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "print(optimal_model.print_topics(num_words=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
